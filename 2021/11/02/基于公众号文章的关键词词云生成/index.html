<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>基于公众号文章的关键词词云生成 - zshuhansan&#039;s blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="钻石胡汉三"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="钻石胡汉三"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="项目简介假期时，作者试着用requests库爬取微信公众号文章进行词云生成，构造headers里的cookie条目时碰到了一些困难。前两天看到selenium这个库，可以通过模拟用户的点击和输入直接获取想要爬取的页面，cookie构造也比较简单，于是重启了这个项目"><meta property="og:type" content="blog"><meta property="og:title" content="基于公众号文章的关键词词云生成"><meta property="og:url" content="http://example.com/2021/11/02/%E5%9F%BA%E4%BA%8E%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0%E7%9A%84%E5%85%B3%E9%94%AE%E8%AF%8D%E8%AF%8D%E4%BA%91%E7%94%9F%E6%88%90/"><meta property="og:site_name" content="zshuhansan&#039;s blog"><meta property="og:description" content="项目简介假期时，作者试着用requests库爬取微信公众号文章进行词云生成，构造headers里的cookie条目时碰到了一些困难。前两天看到selenium这个库，可以通过模拟用户的点击和输入直接获取想要爬取的页面，cookie构造也比较简单，于是重启了这个项目"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://example.com/2021/11/02/%E5%9F%BA%E4%BA%8E%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0%E7%9A%84%E5%85%B3%E9%94%AE%E8%AF%8D%E8%AF%8D%E4%BA%91%E7%94%9F%E6%88%90/%E9%A5%BC%E5%B9%B2.png"><meta property="og:image" content="http://example.com/2021/11/02/%E5%9F%BA%E4%BA%8E%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0%E7%9A%84%E5%85%B3%E9%94%AE%E8%AF%8D%E8%AF%8D%E4%BA%91%E7%94%9F%E6%88%90/%E8%A3%85%E5%A1%AB.png"><meta property="og:image" content="http://example.com/2021/11/02/%E5%9F%BA%E4%BA%8E%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0%E7%9A%84%E5%85%B3%E9%94%AE%E8%AF%8D%E8%AF%8D%E4%BA%91%E7%94%9F%E6%88%90/%E6%95%88%E6%9E%9C%E5%9B%BE.png"><meta property="og:image" content="http://example.com/2021/11/02/%E5%9F%BA%E4%BA%8E%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0%E7%9A%84%E5%85%B3%E9%94%AE%E8%AF%8D%E8%AF%8D%E4%BA%91%E7%94%9F%E6%88%90/%E6%95%88%E6%9E%9C%E5%9B%BE2.png"><meta property="article:published_time" content="2021-11-02T07:50:09.000Z"><meta property="article:modified_time" content="2021-11-05T06:58:56.449Z"><meta property="article:author" content="zshuhansan"><meta property="article:tag" content="爬虫"><meta property="article:tag" content="词云"><meta property="article:tag" content="selenium"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/2021/11/02/%E5%9F%BA%E4%BA%8E%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0%E7%9A%84%E5%85%B3%E9%94%AE%E8%AF%8D%E8%AF%8D%E4%BA%91%E7%94%9F%E6%88%90/%E9%A5%BC%E5%B9%B2.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com/2021/11/02/%E5%9F%BA%E4%BA%8E%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0%E7%9A%84%E5%85%B3%E9%94%AE%E8%AF%8D%E8%AF%8D%E4%BA%91%E7%94%9F%E6%88%90/"},"headline":"基于公众号文章的关键词词云生成","image":["http://example.com/2021/11/02/%E5%9F%BA%E4%BA%8E%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0%E7%9A%84%E5%85%B3%E9%94%AE%E8%AF%8D%E8%AF%8D%E4%BA%91%E7%94%9F%E6%88%90/%E9%A5%BC%E5%B9%B2.png","http://example.com/2021/11/02/%E5%9F%BA%E4%BA%8E%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0%E7%9A%84%E5%85%B3%E9%94%AE%E8%AF%8D%E8%AF%8D%E4%BA%91%E7%94%9F%E6%88%90/%E8%A3%85%E5%A1%AB.png","http://example.com/2021/11/02/%E5%9F%BA%E4%BA%8E%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0%E7%9A%84%E5%85%B3%E9%94%AE%E8%AF%8D%E8%AF%8D%E4%BA%91%E7%94%9F%E6%88%90/%E6%95%88%E6%9E%9C%E5%9B%BE.png","http://example.com/2021/11/02/%E5%9F%BA%E4%BA%8E%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0%E7%9A%84%E5%85%B3%E9%94%AE%E8%AF%8D%E8%AF%8D%E4%BA%91%E7%94%9F%E6%88%90/%E6%95%88%E6%9E%9C%E5%9B%BE2.png"],"datePublished":"2021-11-02T07:50:09.000Z","dateModified":"2021-11-05T06:58:56.449Z","author":{"@type":"Person","name":"zshuhansan"},"publisher":{"@type":"Organization","name":"zshuhansan's blog","logo":{"@type":"ImageObject","url":{"text":"Welcome to my blog"}}},"description":"项目简介假期时，作者试着用requests库爬取微信公众号文章进行词云生成，构造headers里的cookie条目时碰到了一些困难。前两天看到selenium这个库，可以通过模拟用户的点击和输入直接获取想要爬取的页面，cookie构造也比较简单，于是重启了这个项目"}</script><link rel="canonical" href="http://example.com/2021/11/02/%E5%9F%BA%E4%BA%8E%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0%E7%9A%84%E5%85%B3%E9%94%AE%E8%AF%8D%E8%AF%8D%E4%BA%91%E7%94%9F%E6%88%90/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Welcome to my blog</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2021-11-02T07:50:09.000Z" title="2021/11/2 下午3:50:09">2021-11-02</time>发表</span><span class="level-item"><time dateTime="2021-11-05T06:58:56.449Z" title="2021/11/5 下午2:58:56">2021-11-05</time>更新</span><span class="level-item">11 分钟读完 (大约1662个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">基于公众号文章的关键词词云生成</h1><div class="content"><h2 id="项目简介"><a href="#项目简介" class="headerlink" title="项目简介"></a>项目简介</h2><p>假期时，作者试着用requests库爬取微信公众号文章进行词云生成，构造headers里的cookie条目时碰到了一些困难。前两天看到selenium这个库，可以通过模拟用户的点击和输入直接获取想要爬取的页面，cookie构造也比较简单，于是重启了这个项目  </p>
<span id="more"></span>
<h2 id="技术路线"><a href="#技术路线" class="headerlink" title="技术路线"></a>技术路线</h2><p>项目可分为三个部分，信息爬取、信息清洗和词云绘制<br>信息爬取方面，我用了前文提到的<code>selenium</code>这个库，配合<code>re</code>库选出页面的中文内容；信息清洗用到了<code>jieba</code>进行分词，结合网上的stopword和自己的积累进行了无意义词的排除；词云用了<code>cloudword</code>结合<code>matplotlib</code>绘图。  </p>
<h2 id="项目实战"><a href="#项目实战" class="headerlink" title="项目实战"></a>项目实战</h2><h3 id="爬虫部分"><a href="#爬虫部分" class="headerlink" title="爬虫部分"></a>爬虫部分</h3><h4 id="selenium的简单介绍"><a href="#selenium的简单介绍" class="headerlink" title="selenium的简单介绍"></a>selenium的简单介绍</h4><p>selenium需要使用调用其他浏览器的webdriver实现对真人用户操作的模拟，该webdriver需要与对应的本机浏览器版本号一致。<br>其基本的使用方法如下  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver <span class="keyword">import</span> ChromeOptions</span><br><span class="line"></span><br><span class="line"><span class="comment">#为了避免网站对selenium的检测,我们需要在初始化时添加一些参数，此部分放在初始化之前</span></span><br><span class="line">option=ChromeOptions()<span class="comment">#初始化一个 初始化参数类</span></span><br><span class="line"></span><br><span class="line">option.add_experimental_option(<span class="string">&#x27;excludeSwitches&#x27;</span>, [<span class="string">&#x27;enable-automation&#x27;</span>])<span class="comment">#向option这个实例添加内容</span></span><br><span class="line"></span><br><span class="line">target=webdriver.Chrome(<span class="string">&#x27;对应webdriver的路径&#x27;</span>,options=option)<span class="comment">#带参数地创建了一个webdriver实例</span></span><br><span class="line"></span><br><span class="line">target.set_page_load_timeout(<span class="number">30</span>)<span class="comment">#设置单页面加载的最长时间</span></span><br><span class="line"></span><br><span class="line">target.get(<span class="string">&#x27;url&#x27;</span>)<span class="comment">#打开url对应的页面</span></span><br><span class="line"></span><br><span class="line">target.find_element_by_xpath(<span class="string">&#x27;元素的xpath&#x27;</span>)<span class="comment">#通过xpath寻找目标页面元素</span></span><br><span class="line"><span class="comment">#xpath可换为class_name/css_selector/id/link_text等，分别对应不同的寻找页面元素的方式</span></span><br><span class="line"></span><br><span class="line">target.find_element_by_xpath(<span class="string">&#x27;元素的xpath&#x27;</span>).click()<span class="comment">#单击该元素</span></span><br><span class="line">target.find_element_by_xpath(<span class="string">&#x27;元素的xpath&#x27;</span>).send_keys(<span class="string">&#x27;数据&#x27;</span>)<span class="comment">#向元素中输入数据</span></span><br><span class="line"><span class="comment">#通过  元素.函数 的方式可以实现单双击、输入输出等拟人操作</span></span><br><span class="line"></span><br><span class="line">target.get_cookies()<span class="comment">#获得当前页面的cookie</span></span><br><span class="line">target.add_cookie(i)<span class="comment">#向当前页面装载 i 这一条cookie</span></span><br><span class="line">target.delete_all_cookies<span class="comment">#清空当前页面的cookie</span></span><br><span class="line"></span><br><span class="line">target.close()<span class="comment">#关闭当前标签页</span></span><br><span class="line">target.quit()<span class="comment">#关闭所有标签页，标签页只有一个时和close相同</span></span><br></pre></td></tr></table></figure>
<p>更多的操作可参考官方文档等</p>
<h4 id="获取cookie"><a href="#获取cookie" class="headerlink" title="获取cookie"></a>获取cookie</h4><p>在本项目中，用了cookie进行免人工登录，在此之前我们需要人工登录一次并将cookie（json格式）存到本地，使其能够在有效时间内一直使用。<br>图为本地cookie文件，手动装填非常麻烦<br><img src="/2021/11/02/%E5%9F%BA%E4%BA%8E%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0%E7%9A%84%E5%85%B3%E9%94%AE%E8%AF%8D%E8%AF%8D%E4%BA%91%E7%94%9F%E6%88%90/%E9%A5%BC%E5%B9%B2.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver <span class="keyword">import</span> ChromeOptions</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.keys <span class="keyword">import</span> Keys</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"><span class="comment">#此为cookie获取部分</span></span><br><span class="line">target.get(<span class="string">&#x27;https://weixin.sogou.com/&#x27;</span>)<span class="comment">#点进去之后手动登录</span></span><br><span class="line">sleep(<span class="number">30</span>)</span><br><span class="line">cookie=target.get_cookies()</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;cookies.txt&#x27;</span>,<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    json.dump(cookie,f)<span class="comment">#将登陆后页面的cookie存为cookies.txt文件</span></span><br><span class="line">target.close()<span class="comment">#将该页面关闭</span></span><br></pre></td></tr></table></figure>
<h4 id="信息爬取和存储"><a href="#信息爬取和存储" class="headerlink" title="信息爬取和存储"></a>信息爬取和存储</h4><p>获取cookie后我们就可以自动化地爬取和存储信息了，首先要通过cookie绕过登录</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver <span class="keyword">import</span> ChromeOptions</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.keys <span class="keyword">import</span> Keys</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line">stime=<span class="number">1</span><span class="comment">#页面加载好后停顿的时间，按理来说我们应该使其为一个正态分布，均值较小的随机数，每次都随机</span></span><br><span class="line">target.get(<span class="string">&#x27;https://weixin.sogou.com/&#x27;</span>)<span class="comment">#打开页面</span></span><br><span class="line">target.delete_all_cookies()<span class="comment">#删除当前页面的cookie，防止和之后装载的冲突</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;cookies.txt&#x27;</span>,<span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    cookies=json.load(f)<span class="comment">#读取cookie</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> cookies:</span><br><span class="line">    target.add_cookie(i)<span class="comment">#装载cookie</span></span><br><span class="line">sleep(stime)<span class="comment">#停一下</span></span><br><span class="line">target.get(<span class="string">&#x27;https://weixin.sogou.com/&#x27;</span>)<span class="comment">#带着装载好cookie后再次get页面</span></span><br><span class="line">sleep(stime)<span class="comment">#停一下</span></span><br><span class="line">target.find_element_by_xpath(<span class="string">&#x27;//*[@id=&quot;query&quot;]&#x27;</span>).send_keys(<span class="string">&#x27;关键词&#x27;</span>)<span class="comment">#在自己的浏览器中F12选取搜索框，找到后copy xpath填入代码中，使用send_keys方法填入想要搜索的关键词</span></span><br><span class="line">sleep(stime)<span class="comment">#停一下</span></span><br><span class="line">target.find_element_by_xpath(<span class="string">&#x27;//*[@id=&quot;searchForm&quot;]/div/input[3]&#x27;</span>).click()<span class="comment">#点击搜索键，进入搜索结果页面</span></span><br></pre></td></tr></table></figure>
<p>自动填写和登录如图<br><img src="/2021/11/02/%E5%9F%BA%E4%BA%8E%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0%E7%9A%84%E5%85%B3%E9%94%AE%E8%AF%8D%E8%AF%8D%E4%BA%91%E7%94%9F%E6%88%90/%E8%A3%85%E5%A1%AB.png"><br>接下来的部分就很简单了，先读取搜索结果的条数确定爬取文章的数量，在try-except框架下通过<code>click()</code>点开每一篇文章，并使用<code>.page_source</code>获取整个页面的html内容，用<code>re</code>匹配其中所有的中文内容并保存即可。</p>
<h3 id="信息清洗"><a href="#信息清洗" class="headerlink" title="信息清洗"></a>信息清洗</h3><p>没有清洗过的文本，高频词都是些 <code>给/航小萱/点亮/1000个/在看</code> 这样的与搜索内容无关的词，所以我们需要在结果中剔除掉这些内容<br>我目前用的方法比较笨，先用jieba库将所有文本切成一个一个的词，将全部要清洗的词从本地读入为列表，统计词频时，若该词为要清洗的词，不统计。<br>代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> jieba.analyse</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;新冠.txt&#x27;</span>,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    txt=f.read()<span class="comment">#读入所有公众号文章文本</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;stopword.txt&#x27;</span>,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    stopword=f.read()<span class="comment">#读入要清洗的词</span></span><br><span class="line">stopword=stopword.split(<span class="string">&#x27;\n&#x27;</span>)<span class="comment">#转为列表</span></span><br><span class="line"><span class="comment">#统计词频并按频率排序</span></span><br><span class="line">words = jieba.cut(txt, cut_all=<span class="literal">False</span>)<span class="comment">#cut结果是一个可迭代的数据</span></span><br><span class="line">count=&#123;&#125;</span><br><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">    <span class="keyword">if</span> word <span class="keyword">in</span> stopword <span class="keyword">or</span> <span class="built_in">len</span>(word)&lt;<span class="number">2</span>:<span class="comment">#是否统计</span></span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        count[word]=count.get(word,<span class="number">0</span>)+<span class="number">1</span></span><br><span class="line">outcount=<span class="built_in">list</span>(count.items())</span><br><span class="line">outcount.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h3 id="简单绘图"><a href="#简单绘图" class="headerlink" title="简单绘图"></a>简单绘图</h3><p>接下来的就很简单了，设置图的参数等比较麻烦，我就基本上全默认了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line"><span class="keyword">import</span> PIL.Image <span class="keyword">as</span> Image</span><br><span class="line">cloud=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>):</span><br><span class="line">    cloud.append(outcount[i][<span class="number">0</span>])</span><br><span class="line">wordcloud=WordCloud(  background_color=<span class="string">&#x27;white&#x27;</span>,font_path = <span class="string">&#x27;msyh.ttc&#x27;</span>,margin=<span class="number">2</span>).generate(<span class="string">&#x27;/&#x27;</span>.join(cloud))<span class="comment">#generate的参数好像不能是列表(?)</span></span><br><span class="line">plt.imshow(wordcloud)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>效果如图<br><img src="/2021/11/02/%E5%9F%BA%E4%BA%8E%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0%E7%9A%84%E5%85%B3%E9%94%AE%E8%AF%8D%E8%AF%8D%E4%BA%91%E7%94%9F%E6%88%90/%E6%95%88%E6%9E%9C%E5%9B%BE.png"><br><img src="/2021/11/02/%E5%9F%BA%E4%BA%8E%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0%E7%9A%84%E5%85%B3%E9%94%AE%E8%AF%8D%E8%AF%8D%E4%BA%91%E7%94%9F%E6%88%90/%E6%95%88%E6%9E%9C%E5%9B%BE2.png"></p>
<h2 id="总结一下"><a href="#总结一下" class="headerlink" title="总结一下"></a>总结一下</h2><p>项目实现了关键词搜索-爬取公众号文章-数据清洗-词云绘制的流程，但仍然有一些遗憾，以后看着补吧，包括但不限于:出现人机验证后被卡、绘图的自定义功能、清洗和切词的更快速处理…..<br>从昨晚吃完饭到今天的课余时间里完成了还是挺高兴的，乐</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a target="_blank" rel="noopener" href="https://jimzhang.me/2020/03/Python%E4%B8%ADselenium%E5%BA%93%E6%8C%87%E5%AF%BC/">https://jimzhang.me/2020/03/Python%E4%B8%ADselenium%E5%BA%93%E6%8C%87%E5%AF%BC/</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/60852696">https://zhuanlan.zhihu.com/p/60852696</a><br><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1722974">https://cloud.tencent.com/developer/article/1722974</a><br><a target="_blank" rel="noopener" href="https://www.icode9.com/content-1-1105164.html">https://www.icode9.com/content-1-1105164.html</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_30256505/article/details/101171289">https://blog.csdn.net/weixin_30256505/article/details/101171289</a>  </p>
<p>写聚合页抓一堆毫不相干页面来的网站是屑</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>基于公众号文章的关键词词云生成</p><p><a href="http://example.com/2021/11/02/基于公众号文章的关键词词云生成/">http://example.com/2021/11/02/基于公众号文章的关键词词云生成/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>zshuhansan</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2021-11-02</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2021-11-05</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a><a class="link-muted mr-2" rel="tag" href="/tags/%E8%AF%8D%E4%BA%91/">词云</a><a class="link-muted mr-2" rel="tag" href="/tags/selenium/">selenium</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2021/11/05/%E8%AE%A1%E7%BD%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-Socket/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">计网学习笔记-Socket(未完结)</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2021/10/01/%E4%BD%BF%E7%94%A8hexo%E5%88%9B%E5%BB%BA%E5%8D%9A%E5%AE%A2%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%88%B0Gitpages-%E6%A0%91%E8%8E%93%E6%B4%BE%E4%B8%8A/"><span class="level-item">使用hexo创建博客并部署到GitPages/树莓派上(未完结)</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div class="content" id="valine-thread"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script><script>new Valine({
            el: '#valine-thread',
            appId: "rwBgksawhTsNwABrmfsMPz6P-gzGzoHsz",
            appKey: "uJqSMzTcEfaFiNr18pOWrF3B",
            
            
            avatarForce: false,
            meta: ["nick","mail"],
            pageSize: 10,
            lang: "zh-CN",
            visitor: false,
            highlight: true,
            recordIP: false,
            
            
            
            enableQQ: false,
            requiredFields: [],
        });</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.png" alt="钻石胡汉三"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">钻石胡汉三</p><p class="is-size-6 is-block">Beihang undergraduate</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Beijing</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">6</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">0</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">10</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/zshuhansan" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/zshuhansan"><i class="fab fa-github"></i></a></div></div></div><!--!--><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-11-10T06:00:35.000Z">2021-11-10</time></p><p class="title"><a href="/2021/11/10/%E7%BE%8E%E8%B5%9B%E5%87%86%E5%A4%87-LINGO%E7%BC%96%E7%A8%8B/">美赛准备-LINGO编程</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-11-05T07:01:24.000Z">2021-11-05</time></p><p class="title"><a href="/2021/11/05/%E8%AE%A1%E7%BD%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-Socket/">计网学习笔记-Socket(未完结)</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-11-02T07:50:09.000Z">2021-11-02</time></p><p class="title"><a href="/2021/11/02/%E5%9F%BA%E4%BA%8E%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0%E7%9A%84%E5%85%B3%E9%94%AE%E8%AF%8D%E8%AF%8D%E4%BA%91%E7%94%9F%E6%88%90/">基于公众号文章的关键词词云生成</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-10-01T12:00:29.000Z">2021-10-01</time></p><p class="title"><a href="/2021/10/01/%E4%BD%BF%E7%94%A8hexo%E5%88%9B%E5%BB%BA%E5%8D%9A%E5%AE%A2%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%88%B0Gitpages-%E6%A0%91%E8%8E%93%E6%B4%BE%E4%B8%8A/">使用hexo创建博客并部署到GitPages/树莓派上(未完结)</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-31T03:54:41.000Z">2021-08-31</time></p><p class="title"><a href="/2021/08/31/%E7%94%A8py%E5%81%9A%E4%B8%80%E4%B8%AA%E7%AE%80%E6%98%93%E7%9A%84%E5%AE%9D%E5%8F%AF%E6%A2%A6%E4%BD%9C%E6%88%98%E7%B3%BB%E7%BB%9F/">用py做一个简易的宝可梦作战系统(未完结)</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/11/"><span class="level-start"><span class="level-item">十一月 2021</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/10/"><span class="level-start"><span class="level-item">十月 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/08/"><span class="level-start"><span class="level-item">八月 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/LINGO/"><span class="tag">LINGO</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Socket/"><span class="tag">Socket</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hexo/"><span class="tag">hexo</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/selenium/"><span class="tag">selenium</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"><span class="tag">博客搭建</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%88%AC%E8%99%AB/"><span class="tag">爬虫</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BE%8E%E8%B5%9B/"><span class="tag">美赛</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"><span class="tag">计算机网络</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AF%8D%E4%BA%91/"><span class="tag">词云</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"><span class="tag">面向对象</span><span class="tag">1</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Welcome to my blog</a><p class="is-size-7"><span>&copy; 2021 zshuhansan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><a href="zshuhansan.top">京ICP备2021031728</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false});</script></body></html>