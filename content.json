{"pages":[],"posts":[{"title":"使用hexo创建博客并部署到GitPages&#x2F;树莓派上(未完结)","text":"前言搭建这个博客着实费了些时间和精力，踩了不少坑，这篇博文用来记录我的搭建过程，以期记录，也让读者能够少走弯路，避免网上一堆灌水垃圾的误导…项目最后的实现效果也不错，我在两台Win PC上都可以编辑我的博客并即时更新到我的仓库，且外网能正常访问我的博客 基本的技术路线网站框架: Hexo部署仓库: GitPages和我自己的树莓派服务器部署: Nginx内网穿透: 目前是花生壳 实现过程Hexo在Win PC上的安装和基础配置安装依赖项和Hexo本体 Git项目依赖于Git做部署，需要提前下载好。下载地址: https://gitforwindows.org安装就直点确定就好检查Git是否安装完成:命令行输入git --version输出和图差不多就行 Node.JsNode.Js是hexo的依赖项，也需要提前下载并安装下载地址: https://node.js.org/en/download/检查类似Git,输入node -v Hexonodejs还给了我们npm这么个包管理工具，我们可以直接用npm安装hexo，打开命令行，输入npm install -g hexo-cli即可安装，输入hexo -v检查版本确认是否安装成功 初始化和简单配置仍然是打开命令行，我们来初始化我们的本地博客。输入d:转到d盘(其他哪个盘都行)，然后输入hexo init 放博客的文件夹名字等待初始化完成即可。完成后文件夹应该长这样然后cd 文件夹名字先后输入hexo cleanhexo s你就可以在 http://localhost:4000/ 看到一个最初始的博客界面了，它长这个样子 写一篇博文还是命令行界面的博客文件夹目录下，我们可以输入hexo new 博文的名字来创建一篇博文。此时d:/博客文件夹/source/_posts/中会出现一个博文名字.md的文件，支持Markdown语法，我们用顺手的编辑器对博文进行编辑即可。!!注意:插图时应在_post文件夹里新建一个和博文同名的文件夹，将插图放入此文件夹中，博文使用该图时，引用格式应该为![](图片名字.png(也可能是jpg什么的，看你那张图片是什么格式)) 将博客部署到GitPages上Github仓库建立在Github上建立一个仓库，仓库的名字是你的github用户名.github.io 修改部署设置这时候我们需要用到刚才的git了，我们需要生成一个ssh密钥，让github仓库能认出我们这台电脑。首先我们在命令行中执行ssh-keygen -t rsa -C 然后我们打开C盘/用户/用户名/.ssh，用记事本打开id_rsa.puh这个文件，并全选复制其内容。然后我们打开github，点击自己的头像后选择setting，在ssh and gpg keys中选择new ssh key，标题随意，粘贴刚才复制的内容即可。验证:在命令行中执行ssh -T git@github.com,输出末尾句是Hi github用户名,You've successfully .....即可。然后我们来设置hexo设置，在我们之前创建的博客文件夹中，找到\\source_posts_config.yml，打开该文件，找到deploy项,改写成如下形式 1234deploy:- type: git repo: https://github.com/你的github名字/你的github名字.github.io.git branch: master 将博客部署到树莓派上仍然是命令行，我们cd到创建的博客文件夹，执行hexo d，等待完成即可，等待1min，我们就可以在”你的github名字.github.io”这个网站看到你的博客了。 树莓派上Nginx的配置用花生壳进行内网穿透花生壳是我目前用的内网穿透方案","link":"/2021/10/01/%E4%BD%BF%E7%94%A8hexo%E5%88%9B%E5%BB%BA%E5%8D%9A%E5%AE%A2%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%88%B0Gitpages-%E6%A0%91%E8%8E%93%E6%B4%BE%E4%B8%8A/"},{"title":"介绍一下自己，还有这个博客","text":"先自我介绍下我是北航的在读本科生，空间科学专业，做了个标签让介绍更直观一点 这个博客的搭建技术路线这个博客的框架是hexo,跑在我自己的树莓派上，部署方式是nginx，目前用的是sakura frp做内网穿透。唯一的缺点就是我是用内网在往树莓派上传东西，正在寻找比较好的SSH解决方案。 这个博客写点什么技术比如之前做的宝可梦大作业,包括了信息爬取，面向对象以及可视化的;以及本站的建站过程，我都会进行分享，同时可能会写一些数据结构还有计原计网的学习笔记之类(挖坑) 游戏我是个游戏食性很杂的人，什么游戏都玩一点，但是都挺菜的….本站后续可能出点游戏推荐和游戏评价啥的欢迎加我steam!好友代码：1063979847 硬件因为我是台式+笔记本+树莓派的组合,最近虚拟货币又在涨，所以本站有可能出现一些换拆机/装新机的帖,同时我可能会分享一些多端同步文件的内容。","link":"/2021/08/27/%E4%BB%8B%E7%BB%8D%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%EF%BC%8C%E8%BF%98%E6%9C%89%E8%BF%99%E4%B8%AA%E5%8D%9A%E5%AE%A2/"},{"title":"计网学习笔记-Socket(未完结)","text":"计网的学习笔记，用于留档复习和供读者参考(或许)本篇Socket主要是WinSock,也差不多少 Socket是什么socket提供了应用层和传输层间的接口。应用层借助底层向另一端的应用层传输数据或进行控制时，需要调用应用编程接口API，将应用进程控制权和操作系统控制权进行转换。Soket编程就是对这些API进行操作。 Socket怎么用Socket的基本用法像py/c等都对Socket有支持，用法有细微的不同，我在代码段里写的是c的版本，闲了再更新 头文件123#include &lt;stdio.h&gt;#include &lt;winsock2.h&gt;#pragma comment (lib, &quot;ws2_32.lib&quot;) //这一句用来加载 ws2_32.dll 主函数123456789101112131415161718192021int main(){ WSADATA wsaData; //初始化我们要使用的winsock库 //接下来的代码用于检查是否初始化成功 //WSAStartup()返回值为0说明成功 //第一个参数如果写MAKEWORD(2, 1)是调用2.1版本的winsock,我用的是2.2 //WSAStartup()的第二个参数就是我们之前初始化的结构变量wsaData int isright; isright=WSAStartup(MAKEWORD(2, 2), &amp;wsaData); if (isright!=0) { printf(&quot;init failed,check the code&quot;); return -1; } else printf(&quot;init successfully!\\n&quot;);/*正式建立TCP连接的部分，我在后面将分为客户端和服务器端两部分来写*/ WSACleanup();//停止对winsock库的引用 return 0;} Socket客户端程序设计客户端程序流程1.确定目标服务器ip地址和端口号2.创建本地套接字3.与服务器进行连接4.按照应用层协议通信(发送/接收信息)5.关闭/释放连接 客户端的TCP连接部分(之前代码缺失的部分)对于客户端，将(1,2,3,4,5步的代码)填入即可简单运行 创建套接字并连接服务器(1,2,3步)123456789101112//确认并装填目标服务器信息struct sockaddr_in sockAddr;memset(&amp;sockAddr, 0, sizeof(sockAddr)); //将变量sockAddr对应内存空间的每个字节都用0填充，相当于初始化sockAddr.sin_family = AF_INET;sockAddr.sin_addr.s_addr = inet_addr(&quot;服务器的ipv4地址&quot;);sockAddr.sin_port = htons(端口号(不带括号));//创建本地套接字SOCKET sock = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP);//与服务器进行连接connect(sock, (SOCKADDR*)&amp;sockAddr, sizeof(SOCKADDR)); 这一部分的函数方法和数据结构详解如下 123456789101112131415161718192021SOCKET sd = socket(protofamily,type,proto)//创建一个套接字//第一个参数是协议族，对TCP/IP协议时为AF_INET/*第二个参数是套接字的类型，对于TCP/IP，可创建类型为SOCK_STREAM(流式套接字，面向TCP),SOCK_DGRAM(数据报套接字，面向UDP)或者SOCK_RAW(原始套接字，直接面向网络层IP/ICMP/IGMP，需要管理员权限)的套接字*///第三个参数是协议号，默认是0，如果有多个，需要将不同的协议声明对应的协议号struct sockaddr_in { short sin_family; //地址族，AF_INET是internet协议的ipv4 u_short sin_port; //16位的端口号 struct in_addr sin_addr; //32位的ip地址 char sin_zero[8]; //用来储存sockaddr数据};connect(SOCKET sd,struct sockaddr_in* saddr,int saddrlen)//客户端调用来使客户端套接字与saddr指向的服务器地址进行连接//第一个参数是我们之前创建的套接字//第二个参数是struct sockaddr_in的指针变量saddr，其指向的内容是服务器的ip+端口号//第三个参数是struct sockaddr_in变量的大小(占用的字节数) 接收服务器传来的数据(第4步)123char info[MAXBYTE] = { 0 };recv(sock, info, MAXBYTE, NULL);//内容会被存到info这个长255的字符串中 数据的接收函数方法详解如下 123recv(sd,*buf,len,flags)recvfrom(sd,*buf,len,flags,destaddr,addrlen)//没有to和from是TCP和用过connect的UDP的函数，有的就是UDP 向服务器发送数据(第4步)12//第二个参数是指针，第三个是字符串长度send(sd,info,len(info),NULL); 数据的发送函数方法详解如下 123send(sd,*buf,len,flags)sendto(sd,*buf,len,flags,destaddr,addrlen)//没有to和from是TCP和用过connect的UDP的函数，有的就是UDP 关闭/释放套接字(第5步)在插入部分的最后，要关闭/释放所有程序中创建的套接字本示例中为closesocket(sock);函数用法为 1234int closesocket(SOCKET sd)//套接字结构内会记录被多少个进程所引用，调用一次该函数会将此值-1，减到0才算是将该套接字关闭。//此时注意，一个进程的多个线程不重复计数//返回值为0算成功 ip处理客户端可能使用域名或者ip地址访问服务器，而ip协议使用的是32位二进制的ip地址，所以我们需要在程序调用时将ip或域名转换到32位ip 1234567891011inet_addr()//点分式十进制ip转为32位ipgethostbyname()//域名到32位ip地址//注意此处gethostbyname函数返回一个指向hostent结构的指针struct hostent{ char *h_name; //正式主机名 char **h_aliases; //主机别名 int h_addrtype; //主机IP地址类型：IPV4-AF_INET int h_length; //主机IP地址字节长度，对于IPv4是四字节，即32位 char **h_addr_list; //主机的IP地址列表 取[0]为主机ip};#define h_addr h_addr_list[0] 解析协议号客户端可能会使用协议名来指定协议，此时我们需要将协议名转换为协议号使用getprotobyname()实现 123456struct protoent { char *p_name; //正式协议名 char **p_aliases; //协议的别名列表 int p_proto; //协议号 }; Socket服务器端程序设计(在写了在写了)","link":"/2021/11/05/%E8%AE%A1%E7%BD%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-Socket/"},{"title":"基于公众号文章的关键词词云生成","text":"项目简介假期时，作者试着用requests库爬取微信公众号文章进行词云生成，构造headers里的cookie条目时碰到了一些困难。前两天看到selenium这个库，可以通过模拟用户的点击和输入直接获取想要爬取的页面，cookie构造也比较简单，于是重启了这个项目 技术路线项目可分为三个部分，信息爬取、信息清洗和词云绘制信息爬取方面，我用了前文提到的selenium这个库，配合re库选出页面的中文内容；信息清洗用到了jieba进行分词，结合网上的stopword和自己的积累进行了无意义词的排除；词云用了cloudword结合matplotlib绘图。 项目实战爬虫部分selenium的简单介绍selenium需要使用调用其他浏览器的webdriver实现对真人用户操作的模拟，该webdriver需要与对应的本机浏览器版本号一致。其基本的使用方法如下 123456789101112131415161718192021222324252627from selenium import webdriverfrom selenium.webdriver import ChromeOptions#为了避免网站对selenium的检测,我们需要在初始化时添加一些参数，此部分放在初始化之前option=ChromeOptions()#初始化一个 初始化参数类option.add_experimental_option('excludeSwitches', ['enable-automation'])#向option这个实例添加内容target=webdriver.Chrome('对应webdriver的路径',options=option)#带参数地创建了一个webdriver实例target.set_page_load_timeout(30)#设置单页面加载的最长时间target.get('url')#打开url对应的页面target.find_element_by_xpath('元素的xpath')#通过xpath寻找目标页面元素#xpath可换为class_name/css_selector/id/link_text等，分别对应不同的寻找页面元素的方式target.find_element_by_xpath('元素的xpath').click()#单击该元素target.find_element_by_xpath('元素的xpath').send_keys('数据')#向元素中输入数据#通过 元素.函数 的方式可以实现单双击、输入输出等拟人操作target.get_cookies()#获得当前页面的cookietarget.add_cookie(i)#向当前页面装载 i 这一条cookietarget.delete_all_cookies#清空当前页面的cookietarget.close()#关闭当前标签页target.quit()#关闭所有标签页，标签页只有一个时和close相同 更多的操作可参考官方文档等 获取cookie在本项目中，用了cookie进行免人工登录，在此之前我们需要人工登录一次并将cookie（json格式）存到本地，使其能够在有效时间内一直使用。图为本地cookie文件，手动装填非常麻烦 1234567891011from selenium import webdriverfrom selenium.webdriver import ChromeOptionsfrom selenium.webdriver.common.keys import Keysfrom time import sleep#此为cookie获取部分target.get('https://weixin.sogou.com/')#点进去之后手动登录sleep(30)cookie=target.get_cookies()with open('cookies.txt','w') as f: json.dump(cookie,f)#将登陆后页面的cookie存为cookies.txt文件target.close()#将该页面关闭 信息爬取和存储获取cookie后我们就可以自动化地爬取和存储信息了，首先要通过cookie绕过登录 123456789101112131415161718from selenium import webdriverfrom selenium.webdriver import ChromeOptionsfrom selenium.webdriver.common.keys import Keysfrom time import sleepimport jsonstime=1#页面加载好后停顿的时间，按理来说我们应该使其为一个正态分布，均值较小的随机数，每次都随机target.get('https://weixin.sogou.com/')#打开页面target.delete_all_cookies()#删除当前页面的cookie，防止和之后装载的冲突with open('cookies.txt','r') as f: cookies=json.load(f)#读取cookiefor i in cookies: target.add_cookie(i)#装载cookiesleep(stime)#停一下target.get('https://weixin.sogou.com/')#带着装载好cookie后再次get页面sleep(stime)#停一下target.find_element_by_xpath('//*[@id=&quot;query&quot;]').send_keys('关键词')#在自己的浏览器中F12选取搜索框，找到后copy xpath填入代码中，使用send_keys方法填入想要搜索的关键词sleep(stime)#停一下target.find_element_by_xpath('//*[@id=&quot;searchForm&quot;]/div/input[3]').click()#点击搜索键，进入搜索结果页面 自动填写和登录如图接下来的部分就很简单了，先读取搜索结果的条数确定爬取文章的数量，在try-except框架下通过click()点开每一篇文章，并使用.page_source获取整个页面的html内容，用re匹配其中所有的中文内容并保存即可。 信息清洗没有清洗过的文本，高频词都是些 给/航小萱/点亮/1000个/在看 这样的与搜索内容无关的词，所以我们需要在结果中剔除掉这些内容我目前用的方法比较笨，先用jieba库将所有文本切成一个一个的词，将全部要清洗的词从本地读入为列表，统计词频时，若该词为要清洗的词，不统计。代码如下 1234567891011121314151617import jiebaimport jieba.analysewith open('新冠.txt','r',encoding='utf-8') as f: txt=f.read()#读入所有公众号文章文本with open('stopword.txt','r',encoding='utf-8') as f: stopword=f.read()#读入要清洗的词stopword=stopword.split('\\n')#转为列表#统计词频并按频率排序words = jieba.cut(txt, cut_all=False)#cut结果是一个可迭代的数据count={}for word in words: if word in stopword or len(word)&lt;2:#是否统计 continue else: count[word]=count.get(word,0)+1outcount=list(count.items())outcount.sort(key=lambda x: x[1], reverse=True) 简单绘图接下来的就很简单了，设置图的参数等比较麻烦，我就基本上全默认了 12345678910import matplotlib.pyplot as plt from wordcloud import WordCloudimport PIL.Image as Imagecloud=[]for i in range(50): cloud.append(outcount[i][0])wordcloud=WordCloud( background_color='white',font_path = 'msyh.ttc',margin=2).generate('/'.join(cloud))#generate的参数好像不能是列表(?)plt.imshow(wordcloud)plt.axis('off')plt.show() 效果如图 总结一下项目实现了关键词搜索-爬取公众号文章-数据清洗-词云绘制的流程，但仍然有一些遗憾，以后看着补吧，包括但不限于:出现人机验证后被卡、绘图的自定义功能、清洗和切词的更快速处理…..从昨晚吃完饭到今天的课余时间里完成了还是挺高兴的，乐 参考链接https://jimzhang.me/2020/03/Python%E4%B8%ADselenium%E5%BA%93%E6%8C%87%E5%AF%BC/https://zhuanlan.zhihu.com/p/60852696https://cloud.tencent.com/developer/article/1722974https://www.icode9.com/content-1-1105164.htmlhttps://blog.csdn.net/weixin_30256505/article/details/101171289 写聚合页抓一堆毫不相干页面来的网站是屑","link":"/2021/11/02/%E5%9F%BA%E4%BA%8E%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0%E7%9A%84%E5%85%B3%E9%94%AE%E8%AF%8D%E8%AF%8D%E4%BA%91%E7%94%9F%E6%88%90/"},{"title":"用py做一个简易的宝可梦作战系统(未完结)","text":"项目介绍这个项目是我大一下学期《大学计算机基础》的结课大作业选题之一，要求…. 这篇博文将实现过程分为如下的几个部分 数据爬取 面向对象的对象设计 对战界面设计 对战计算设计 数据爬取 爬虫技术路线由于第一到第八世代宝可梦共800余只，爬取信息条目数量较少，所以我使用了比较基础的requests+BeautifulSoup4+re组合，进行宝可梦信息爬取和提取，配合OS和Numpy进行保存。 爬虫爬取信息确定 既然是要做战斗系统，那么就需要考虑宝可梦的属性，攻防数值，技能列表以及技能的各项属性。而经验值和进化的问题由于各世代有些微差异，该项目将不会涉及。处于以上思考，我将爬取分成了以下两个部分。1.宝可梦信息爬取:内容包括宝可梦名称、头像、攻防和血量属性(最小值和最大值)、技能列表。 2.宝可梦技能信息爬取:内容包括技能属性、PP、伤害上下限以及技能附带的特殊效果(用正则表达式进行匹配) 爬虫实现Whenever我们使用爬虫，都应该先检查网站robots协议，经检查协议为空，那么我们就可以开始我们的信息爬取了。我的两只爬虫大致思路都相同: 1.try-except模式下先链接每只宝可梦/每个技能网页并获取内容，失败时在终端打印”xx宝可梦/技能爬取失败” 1234567891011121314userkv={'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36', 'accept-language':'zh-CN,zh;q=0.9' }#这一部分是我们打开网页时向网页表明身份的键值对。 #一些服务器会自动拒绝掉爬虫的http请求，所以我们要对爬虫做一些伪装。 #我们可以在浏览器中打开网页，F12后在Network中找到页面条目，在其中找到requests-headers项目（如图），替换即可。def getHTMLText(url): try: r=requests.get(url,timeout=30,headers=userkv) r.raise_for_status()#链接出错时会抛出一个错误跳转到except r.encoding='utf-8'#确定编码方式为utf-8 return r.text#返回网页HTML内容 except: return '' 2.得到网页内容后按照正则表达式匹配以及网页html标签的排列规律，提取信息并存取 爬取宝可梦信息首先我们进入宝可梦图鉴，F12检查页面属性 在宝可梦名称所在标签有对应的宝可梦页面链接后缀，直接进行访问即可。而在每个宝可梦的单独页面中，可以通过正则表达式匹配标签对应的注释，判断如: if (表达式) in 标签.attrs，找到标签特点即可 爬取宝可梦技能信息宝可梦的技能列表爬取就更简单了，直接在招式图鉴里把信息录下即可。 爬取结果展示宝可梦基础信息技能基础信息 面向对象面向对象是为了对战调用信息更加完善，主要分为单个宝可梦及其技能以及整个背包的设计，主要还是通过py的列表(即哈希表)来实现。同时在初始化前需要读取之前保存的数据。 单个宝可梦的面向对象特简单，我放个代码段。 1234567891011121314151617181920212223242526272829303132pokemen_path='D:/OneDrive/python垃圾代码/基于requests获得宝可梦信息/pokemen.xlsx'all_pokemen=pd.read_excel(pokemen_path)all_pokemen.set_index('name',inplace=True)all_pokemen.to_excel(pokemen_path)def dice(ran):#在已知能力值区间内取出随机值 min=int(ran.split(' - ')[0]) max=int(ran.split(' - ')[1]) if min &lt;max:ret=np.random.randint(min,max) else:ret=min return retclass Pokemen(): def __init__(self,pokemen,skill): #pokemen是Dataframe,skill是技能名列表 self.name=pokemen.name self.attr=pokemen['attr'] self.hp=dice(pokemen['HP']) self.f_hp=self.hp self.atk=dice(pokemen['攻击']) self.defense=dice(pokemen['防御']) self.s_atk=dice(pokemen['特攻']) self.s_defense=dice(pokemen['特防']) self.speed=dice(pokemen['速度']) self.skill={} self.neg=''#宝可梦的负面状态 for i in skill: try: self.skill[i]=Skill(all_skill.loc[i]) except: print('\\n%s技能初始化失败\\n'%i) print(&quot;%s初始化成功&quot;%self.name) 宝可梦技能还有背包的初始化 类似地，唯一注意的就是要有pp(或其他战斗属性)最大值和战时状态值的区分 未完待续….. py的列表真是好py就是最好的语言！！！","link":"/2021/08/31/%E7%94%A8py%E5%81%9A%E4%B8%80%E4%B8%AA%E7%AE%80%E6%98%93%E7%9A%84%E5%AE%9D%E5%8F%AF%E6%A2%A6%E4%BD%9C%E6%88%98%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"博客搭建","slug":"博客搭建","link":"/tags/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"},{"name":"计算机网络","slug":"计算机网络","link":"/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"Socket","slug":"Socket","link":"/tags/Socket/"},{"name":"爬虫","slug":"爬虫","link":"/tags/%E7%88%AC%E8%99%AB/"},{"name":"词云","slug":"词云","link":"/tags/%E8%AF%8D%E4%BA%91/"},{"name":"selenium","slug":"selenium","link":"/tags/selenium/"},{"name":"面向对象","slug":"面向对象","link":"/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"}],"categories":[]}